{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdee5b3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdee5b3e",
        "outputId": "8ac5319c-23d2-493b-c4c9-851760e8f76e"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/SKfaizan-786/EAST-text-detection.git\n",
        "%cd EAST-text-detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KWZeur-c5X1y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KWZeur-c5X1y",
        "outputId": "12f095f2-df89-420d-f589-1dae571cde86"
      },
      "outputs": [],
      "source": [
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fMRA2bieNLd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMRA2bieNLd4",
        "outputId": "5bf8b852-fea9-4caa-d1f0-4b298c69b375"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from shapely.geometry import Polygon\n",
        "from shapely.affinity import scale\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "\n",
        "# Base paths inside the cloned repo\n",
        "DATA_DIR = \"data/icdar2015\"\n",
        "TRAIN_IMG_DIR = f\"{DATA_DIR}/train_images\"\n",
        "TRAIN_LABEL_DIR = f\"{DATA_DIR}/train_labels\"\n",
        "TRAIN_MAP_DIR = f\"{DATA_DIR}/train_maps\"\n",
        "os.makedirs(TRAIN_MAP_DIR, exist_ok=True)\n",
        "\n",
        "TEST_IMG_DIR = f\"{DATA_DIR}/test_images\"\n",
        "TEST_LABEL_DIR = f\"{DATA_DIR}/test_labels\"\n",
        "TEST_MAP_DIR = f\"{DATA_DIR}/test_maps\"\n",
        "os.makedirs(TEST_MAP_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Train images:\", len(glob(f\"{TRAIN_IMG_DIR}/*.jpg\")))\n",
        "print(\"Train labels:\", len(glob(f\"{TRAIN_LABEL_DIR}/*.txt\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S81Dk3ATNM6X",
      "metadata": {
        "id": "S81Dk3ATNM6X"
      },
      "outputs": [],
      "source": [
        "def parse_label_file(label_path):\n",
        "    \"\"\"\n",
        "    Parses an ICDAR2015 label txt file and returns a list of quads.\n",
        "    Each quad is [(x1,y1),(x2,y2),(x3,y3),(x4,y4)].\n",
        "    \"\"\"\n",
        "    quads = []\n",
        "    with open(label_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split(',')\n",
        "            if len(parts) >= 8:\n",
        "                coords = list(map(float, parts[:8]))\n",
        "                quad = [(coords[i], coords[i+1]) for i in range(0, 8, 2)]\n",
        "                quads.append(quad)\n",
        "    return quads\n",
        "\n",
        "def canonicalize_quad(quad):\n",
        "    \"\"\"\n",
        "    Return a consistent clockwise ordering of quad vertices starting\n",
        "    from the top-left (approx).\n",
        "    quad: list of 4 (x,y) tuples\n",
        "    \"\"\"\n",
        "    pts = np.array(quad, dtype=np.float32)\n",
        "    cx, cy = np.mean(pts, axis=0)\n",
        "    angles = np.arctan2(pts[:,1] - cy, pts[:,0] - cx)\n",
        "    order = np.argsort(angles)\n",
        "    pts = pts[order]\n",
        "    sums = pts[:,0] + pts[:,1]\n",
        "    start = np.argmin(sums)\n",
        "    pts = np.roll(pts, -start, axis=0)\n",
        "    return pts.tolist()\n",
        "\n",
        "def shortest_edge_length(quad):\n",
        "    q = np.array(quad, dtype=np.float32)\n",
        "    lengths = []\n",
        "    for i in range(4):\n",
        "        p1 = q[i]\n",
        "        p2 = q[(i+1)%4]\n",
        "        lengths.append(np.linalg.norm(p1 - p2))\n",
        "    return float(min(lengths))\n",
        "\n",
        "def shrink_quad(quad, ratio=0.3):\n",
        "    \"\"\"\n",
        "    Shrink quadrilateral inward using shapely.\n",
        "    ratio ~0.3 recommended in EAST paper.\n",
        "    \"\"\"\n",
        "    poly = Polygon(quad)\n",
        "    if not poly.is_valid:\n",
        "        return poly\n",
        "    return scale(poly, xfact=1-ratio, yfact=1-ratio, origin='centroid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vqo4MWOPOfVX",
      "metadata": {
        "id": "Vqo4MWOPOfVX"
      },
      "outputs": [],
      "source": [
        "def generate_maps_with_nmap(img, quads, shrink_ratio=0.3):\n",
        "    \"\"\"\n",
        "    Returns score_map, geo_map, n_map.\n",
        "    n_map is same HxW single channel: N_Q* value for text pixels, 0 outside.\n",
        "    \"\"\"\n",
        "    H, W = img.shape[:2]\n",
        "    score_map = np.zeros((H, W), dtype=np.uint8)\n",
        "    geo_map   = np.zeros((H, W, 8), dtype=np.float32)\n",
        "    n_map     = np.zeros((H, W), dtype=np.float32)\n",
        "\n",
        "    for quad in quads:\n",
        "        quad = canonicalize_quad(quad)\n",
        "        \n",
        "        min_edge = shortest_edge_length(quad)\n",
        "        N_q = 4.0 * min_edge\n",
        "\n",
        "        shrunk_poly = shrink_quad(quad, shrink_ratio)\n",
        "        if shrunk_poly.is_empty:\n",
        "            continue\n",
        "\n",
        "        pts = np.array(list(shrunk_poly.exterior.coords)[:-1], dtype=np.int32)\n",
        "        mask = np.zeros((H, W), dtype=np.uint8)\n",
        "        cv2.fillPoly(mask, [pts], 1)\n",
        "        ys, xs = np.where(mask == 1)\n",
        "\n",
        "        score_map[ys, xs] = 1\n",
        "        n_map[ys, xs] = N_q\n",
        "\n",
        "        quad_arr = np.array(quad, dtype=np.float32)\n",
        "        for y, x in zip(ys, xs):\n",
        "            for k in range(4):\n",
        "                dx = quad_arr[k,0] - x\n",
        "                dy = quad_arr[k,1] - y\n",
        "                geo_map[y,x,2*k]   = dx\n",
        "                geo_map[y,x,2*k+1] = dy\n",
        "\n",
        "    return score_map, geo_map, n_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6JH0gcDO4EH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6JH0gcDO4EH",
        "outputId": "581b923e-f8df-4e54-9747-8523276cd703"
      },
      "outputs": [],
      "source": [
        "sample_imgs = sorted(glob(f\"{TRAIN_IMG_DIR}/*.jpg\"))[:5]\n",
        "for img_path in sample_imgs:\n",
        "    name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    label_path = os.path.join(TRAIN_LABEL_DIR, f\"gt_{name}.txt\")\n",
        "    img = cv2.imread(img_path)\n",
        "    quads = parse_label_file(label_path)\n",
        "    score_map, geo_map, n_map = generate_maps_with_nmap(img, quads)\n",
        "\n",
        "    np.save(os.path.join(TRAIN_MAP_DIR, f\"{name}_score.npy\"), score_map)\n",
        "    np.save(os.path.join(TRAIN_MAP_DIR, f\"{name}_geo.npy\"), geo_map)\n",
        "    np.save(os.path.join(TRAIN_MAP_DIR, f\"{name}_nmap.npy\"), n_map)\n",
        "\n",
        "print(\"✅ Saved 5 sample maps to train_maps/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Df2eWp9SPEfv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Df2eWp9SPEfv",
        "outputId": "8f9fa4ed-2361-4296-a88a-e991903187c1"
      },
      "outputs": [],
      "source": [
        "# visualize one example\n",
        "idx = 0\n",
        "img_path = sample_imgs[idx]\n",
        "name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "img = cv2.imread(img_path)[:,:,::-1]  # BGR->RGB\n",
        "score_map = np.load(os.path.join(TRAIN_MAP_DIR, f\"{name}_score.npy\"))\n",
        "nmap = np.load(os.path.join(TRAIN_MAP_DIR, f\"{name}_nmap.npy\"))\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
        "ax1.imshow(img); ax1.set_title('Image'); ax1.axis('off')\n",
        "ax2.imshow(score_map, cmap='gray'); ax2.set_title('Score Map'); ax2.axis('off')\n",
        "ax3.imshow(nmap, cmap='jet'); ax3.set_title('Normalization Map'); ax3.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QoRsNpl5PoyO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoRsNpl5PoyO",
        "outputId": "eec739da-b318-43c1-cd89-a7486d74c281"
      },
      "outputs": [],
      "source": [
        "def process_split(img_dir, label_dir, out_dir):\n",
        "    img_paths = sorted(glob(f\"{img_dir}/*.jpg\"))\n",
        "    for img_path in img_paths:\n",
        "        name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        label_path = os.path.join(label_dir, f\"gt_{name}.txt\")\n",
        "        if not os.path.exists(label_path):\n",
        "            continue\n",
        "        img = cv2.imread(img_path)\n",
        "        quads = parse_label_file(label_path)\n",
        "        score_map, geo_map, n_map = generate_maps_with_nmap(img, quads)\n",
        "        np.save(os.path.join(out_dir, f\"{name}_score.npy\"), score_map)\n",
        "        np.save(os.path.join(out_dir, f\"{name}_geo.npy\"), geo_map)\n",
        "        np.save(os.path.join(out_dir, f\"{name}_nmap.npy\"), n_map)\n",
        "\n",
        "# Process training and test sets\n",
        "process_split(TRAIN_IMG_DIR, TRAIN_LABEL_DIR, TRAIN_MAP_DIR)\n",
        "process_split(TEST_IMG_DIR, TEST_LABEL_DIR, TEST_MAP_DIR)\n",
        "print(\"✅ Finished generating score, geometry, and normalization maps for all images.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "east_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
