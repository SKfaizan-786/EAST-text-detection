{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ed2e8f5",
      "metadata": {
        "id": "6ed2e8f5",
        "outputId": "e09b9668-bde8-45b0-91d2-1e7f4ff1bd01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Now in: c:\\Users\\faizan\\Desktop\\EAST\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"..\")  # move up from notebooks to repo root\n",
        "print(\"Now in:\", os.getcwd())\n",
        "# Add project root to sys.path so 'src' can be imported\n",
        "import sys\n",
        "project_root = os.path.abspath(os.getcwd())\n",
        "if project_root not in sys.path:\n",
        "    sys.path.append(project_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80fded25",
      "metadata": {
        "id": "80fded25",
        "outputId": "68fa4d87-b1d6-479d-9e72-29f6985fc3af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\faizan\\Desktop\\EAST\n",
            "Dataset length: 1000\n",
            "First 3 image paths: ['data/icdar2015/train_images\\\\img_1.jpg', 'data/icdar2015/train_images\\\\img_10.jpg', 'data/icdar2015/train_images\\\\img_100.jpg']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "from src.dataset import EASTDataset\n",
        "\n",
        "ds = EASTDataset(\"data/icdar2015/train_images\", \"data/icdar2015/train_maps\", size=512)\n",
        "\n",
        "print(\"Dataset length:\", len(ds))\n",
        "print(\"First 3 image paths:\", ds.img_paths[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cae46cd",
      "metadata": {
        "id": "7cae46cd",
        "outputId": "cd658b8f-b14f-43e2-e7c4-eadcaffa6f65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images : torch.Size([4, 3, 512, 512])\n",
            "Scores : torch.Size([4, 1, 512, 512])\n",
            "Geos   : torch.Size([4, 8, 512, 512])\n",
            "Nmaps  : torch.Size([4, 1, 512, 512])\n",
            "Image range: -2.1179039478302 to 2.640000104904175\n",
            "Score unique values: tensor([0., 1.])\n",
            "Geo stats: mean 0.0132293701171875 std 7.47803258895874\n",
            "Nmap stats (on positive pixels): mean 127.58235168457031 std 35.18562698364258\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from src.dataset import EASTDataset\n",
        "\n",
        "# Create a small dataset instance\n",
        "train_dataset = EASTDataset(\n",
        "    img_dir=\"data/icdar2015/train_images\",\n",
        "    map_dir=\"data/icdar2015/train_maps\",\n",
        "    size=512,              # keep same as paper\n",
        "    training=True          # enable random cropping/augmentation\n",
        ")\n",
        "\n",
        "# Try a small dataloader\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "# Fetch one batch, now including the nmap\n",
        "imgs, scores, geos, nmaps = next(iter(train_loader))\n",
        "\n",
        "# Print shapes to verify\n",
        "print(\"Images :\", imgs.shape)    # expect [B, 3, 512, 512]\n",
        "print(\"Scores :\", scores.shape)  # expect [B, 1, 512, 512]\n",
        "print(\"Geos   :\", geos.shape)    # expect [B, 8, 512, 512]\n",
        "print(\"Nmaps  :\", nmaps.shape)   # expect [B, 1, 512, 512]\n",
        "\n",
        "# Check value ranges and properties\n",
        "print(\"Image range:\", imgs.min().item(), \"to\", imgs.max().item())\n",
        "print(\"Score unique values:\", torch.unique(scores))\n",
        "print(\"Geo stats: mean\", geos.mean().item(), \"std\", geos.std().item())\n",
        "\n",
        "# Verify nmap has non-zero values where score is positive\n",
        "print(\"Nmap stats (on positive pixels): mean\", nmaps[scores > 0].mean().item(), \"std\", nmaps[scores > 0].std().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74fb9abd",
      "metadata": {
        "id": "74fb9abd",
        "outputId": "58f18bc8-5741-4bc9-daf1-9035fdf58a4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\faizan/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score map: torch.Size([1, 1, 512, 512])\n",
            "Geo map: torch.Size([1, 8, 512, 512])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from src.model import EAST\n",
        "\n",
        "model = EAST(pretrained=False)\n",
        "dummy = torch.randn(1, 3, 512, 512)  # batch of one\n",
        "score, geo = model(dummy)\n",
        "\n",
        "print(\"Score map:\", score.shape)  # expect [1, 1, 512, 512]\n",
        "print(\"Geo map:\", geo.shape)      # expect [1, 8, 512, 512]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e40f27a",
      "metadata": {
        "id": "7e40f27a",
        "outputId": "e6479454-cd29-4047-9300-a8f466f46d6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total loss: 0.1503923237323761\n",
            "Score loss: 0.020851217210292816\n",
            "Geo loss  : 0.12954111397266388\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from src.model import EAST\n",
        "from src.losses import EASTLoss\n",
        "\n",
        "# Assuming imgs, scores, geos, and nmaps are already loaded from your DataLoader test.\n",
        "# If not, you'd need to run the DataLoader test cell again to get these variables.\n",
        "# You might want to move these to a CUDA device if available.\n",
        "# imgs = imgs.to('cuda')\n",
        "# ... and so on for the other tensors\n",
        "\n",
        "# Instantiate the model and criterion\n",
        "model = EAST(pretrained=True)  # Use pretrained=True to follow the paper's method\n",
        "model.eval()  # Set model to evaluation mode for a clean forward pass test\n",
        "\n",
        "# Perform a forward pass to get predictions\n",
        "with torch.no_grad():\n",
        "    pred_score, pred_geo = model(imgs)\n",
        "\n",
        "# Instantiate the loss function\n",
        "criterion = EASTLoss()\n",
        "\n",
        "# Compute the loss using your predictions and ground truth maps\n",
        "total_loss, score_loss, geo_loss = criterion(pred_score, pred_geo, scores, geos, nmaps)\n",
        "\n",
        "# Print the results\n",
        "print(\"Total loss:\", total_loss.item())\n",
        "print(\"Score loss:\", score_loss.item())\n",
        "print(\"Geo loss  :\", geo_loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SKfaizan-786/EAST-text-detection.git\n",
        "%cd EAST-text-detection"
      ],
      "metadata": {
        "id": "OlUpMdyzkInL",
        "outputId": "af8b6265-be95-40bf-fe62-793245014a8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OlUpMdyzkInL",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EAST-text-detection'...\n",
            "remote: Enumerating objects: 7704, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 7704 (delta 15), reused 16 (delta 5), pack-reused 7670 (from 1)\u001b[K\n",
            "Receiving objects: 100% (7704/7704), 307.15 MiB | 36.85 MiB/s, done.\n",
            "Resolving deltas: 100% (4647/4647), done.\n",
            "Updating files: 100% (7515/7515), done.\n",
            "/content/EAST-text-detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train"
      ],
      "metadata": {
        "id": "q7nW_PsYlsEC",
        "outputId": "7030f4f8-6225-4169-ea3e-2e3e86978320",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "q7nW_PsYlsEC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 900,  Val size: 100\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 118MB/s]\n",
            "Training on 900 images and validating on 100 images for 100 epochs\n",
            "Epoch 1/100: 100%|█| 225/225 [02:42<00:00,  1.39it/s, total=0.1345, score=0.0551\n",
            "Epoch 1 | train loss 0.0950 | val loss 0.1001\n",
            "✅ New best model saved with val loss: 0.1001\n",
            "Epoch 2/100: 100%|█| 225/225 [02:38<00:00,  1.42it/s, total=0.1810, score=0.0808\n",
            "Epoch 2 | train loss 0.0945 | val loss 0.0834\n",
            "✅ New best model saved with val loss: 0.0834\n",
            "Epoch 3/100: 100%|█| 225/225 [02:31<00:00,  1.49it/s, total=0.0751, score=0.0176\n",
            "Epoch 3 | train loss 1476.6351 | val loss 0.0967\n",
            "Epoch 4/100: 100%|█| 225/225 [02:24<00:00,  1.56it/s, total=0.1641, score=0.0456\n",
            "Epoch 4 | train loss 0.0978 | val loss 0.0920\n",
            "Epoch 5/100: 100%|█| 225/225 [02:20<00:00,  1.60it/s, total=0.4534, score=0.0714\n",
            "Epoch 5 | train loss 2411.1412 | val loss 0.3903\n",
            "Epoch 6/100: 100%|█| 225/225 [02:15<00:00,  1.66it/s, total=0.1056, score=0.0251\n",
            "Epoch 6 | train loss 0.1203 | val loss 0.0961\n",
            "Epoch 7/100: 100%|█| 225/225 [02:10<00:00,  1.72it/s, total=0.0997, score=0.0147\n",
            "Epoch 7 | train loss 0.1093 | val loss 0.0893\n",
            "Epoch 8/100: 100%|█| 225/225 [02:06<00:00,  1.78it/s, total=0.0894, score=0.0210\n",
            "Epoch 8 | train loss 0.1080 | val loss 0.0882\n",
            "Epoch 9/100: 100%|█| 225/225 [02:04<00:00,  1.81it/s, total=0.1302, score=0.0809\n",
            "Epoch 9 | train loss 0.1042 | val loss 0.0859\n",
            "Epoch 10/100: 100%|█| 225/225 [02:03<00:00,  1.82it/s, total=0.0900, score=0.048\n",
            "Epoch 10 | train loss 1163.6369 | val loss 0.7827\n",
            "Epoch 11/100: 100%|█| 225/225 [02:04<00:00,  1.81it/s, total=0.2790, score=0.167\n",
            "Epoch 11 | train loss 0.4513 | val loss 0.3153\n",
            "Epoch 12/100: 100%|█| 225/225 [02:03<00:00,  1.82it/s, total=0.2388, score=0.123\n",
            "Epoch 12 | train loss 0.3884 | val loss 0.3607\n",
            "🛑 Early stopping at epoch 12. No improvement for 10 epochs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train"
      ],
      "metadata": {
        "id": "lfHRFt3B0xLK",
        "outputId": "76b1732f-bb75-402f-fbfc-2174ac8a2e92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lfHRFt3B0xLK",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 900,  Val size: 100\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 143MB/s]\n",
            "Training on 900 images | validating on 100 images\n",
            "Device: cuda\n",
            "Epoch 1/100: 100%|█| 225/225 [03:02<00:00,  1.23it/s, total=0.1162, score=0.0350\n",
            "Epoch 1 | train 0.0956 | val 0.0879\n",
            "✅ New best model saved with val loss 0.0879\n",
            "Epoch 2/100: 100%|█| 225/225 [02:56<00:00,  1.27it/s, total=0.0581, score=0.0078\n",
            "Epoch 2 | train 0.0919 | val 0.0900\n",
            "Epoch 3/100: 100%|█| 225/225 [02:49<00:00,  1.33it/s, total=0.0782, score=0.0142\n",
            "Epoch 3 | train 0.0868 | val 0.0858\n",
            "✅ New best model saved with val loss 0.0858\n",
            "Epoch 4/100: 100%|█| 225/225 [02:41<00:00,  1.39it/s, total=0.2410, score=0.0233\n",
            "Epoch 4 | train 0.0843 | val 0.0718\n",
            "✅ New best model saved with val loss 0.0718\n",
            "Epoch 5/100: 100%|█| 225/225 [02:37<00:00,  1.43it/s, total=0.0359, score=0.0037\n",
            "Epoch 5 | train 0.0866 | val 0.0801\n",
            "Epoch 6/100: 100%|█| 225/225 [02:30<00:00,  1.49it/s, total=0.0633, score=0.0254\n",
            "Epoch 6 | train 0.0854 | val 0.0787\n",
            "Epoch 7/100: 100%|█| 225/225 [02:28<00:00,  1.52it/s, total=0.0760, score=0.0121\n",
            "Epoch 7 | train 0.0825 | val 0.0784\n",
            "Epoch 8/100: 100%|█| 225/225 [02:24<00:00,  1.56it/s, total=0.0547, score=0.0058\n",
            "Epoch 8 | train 0.0865 | val 0.0749\n",
            "LR reduced from 0.000500 to 0.000250\n",
            "Epoch 9/100: 100%|█| 225/225 [02:17<00:00,  1.64it/s, total=0.0268, score=0.0051\n",
            "Epoch 9 | train 0.0847 | val 0.0723\n",
            "Epoch 10/100: 100%|█| 225/225 [02:18<00:00,  1.62it/s, total=0.0626, score=0.003\n",
            "Epoch 10 | train 0.0804 | val 0.0890\n",
            "Epoch 11/100: 100%|█| 225/225 [02:16<00:00,  1.65it/s, total=0.0466, score=0.012\n",
            "Epoch 11 | train 0.0798 | val 0.0673\n",
            "✅ New best model saved with val loss 0.0673\n",
            "Epoch 12/100: 100%|█| 225/225 [02:15<00:00,  1.65it/s, total=22472.8477, score=0\n",
            "Epoch 12 | train 99.9581 | val 0.0691\n",
            "Epoch 13/100: 100%|█| 225/225 [02:12<00:00,  1.70it/s, total=0.0649, score=0.004\n",
            "Epoch 13 | train 0.0884 | val 0.0915\n",
            "Epoch 14/100: 100%|█| 225/225 [02:10<00:00,  1.72it/s, total=0.0541, score=0.003\n",
            "Epoch 14 | train 0.0802 | val 0.0816\n",
            "Epoch 15/100: 100%|█| 225/225 [02:17<00:00,  1.64it/s, total=0.1602, score=0.012\n",
            "Epoch 15 | train 0.0757 | val 0.0837\n",
            "LR reduced from 0.000250 to 0.000125\n",
            "Epoch 16/100: 100%|█| 225/225 [02:16<00:00,  1.65it/s, total=0.0665, score=0.008\n",
            "Epoch 16 | train 319.7748 | val 0.0845\n",
            "Epoch 17/100: 100%|█| 225/225 [02:17<00:00,  1.64it/s, total=0.0246, score=0.005\n",
            "Epoch 17 | train 298.4755 | val 0.0982\n",
            "Epoch 18/100: 100%|█| 225/225 [02:13<00:00,  1.68it/s, total=0.0318, score=0.004\n",
            "Epoch 18 | train 0.0761 | val 0.0691\n",
            "Epoch 19/100: 100%|█| 225/225 [02:13<00:00,  1.69it/s, total=0.0542, score=0.003\n",
            "Epoch 19 | train 0.0812 | val 0.0790\n",
            "LR reduced from 0.000125 to 0.000063\n",
            "Epoch 20/100: 100%|█| 225/225 [02:14<00:00,  1.67it/s, total=0.0586, score=0.004\n",
            "Epoch 20 | train 846.4023 | val 0.0622\n",
            "✅ New best model saved with val loss 0.0622\n",
            "Epoch 21/100: 100%|█| 225/225 [02:15<00:00,  1.66it/s, total=0.0506, score=0.004\n",
            "Epoch 21 | train 0.0734 | val 0.0761\n",
            "Epoch 22/100: 100%|█| 225/225 [02:16<00:00,  1.65it/s, total=0.0579, score=0.003\n",
            "Epoch 22 | train 0.0686 | val 0.0629\n",
            "Epoch 23/100: 100%|█| 225/225 [02:16<00:00,  1.65it/s, total=0.0325, score=0.003\n",
            "Epoch 23 | train 0.0718 | val 0.0732\n",
            "Epoch 24/100: 100%|█| 225/225 [02:16<00:00,  1.64it/s, total=0.2143, score=0.003\n",
            "Epoch 24 | train 0.0805 | val 0.0643\n",
            "LR reduced from 0.000063 to 0.000031\n",
            "Epoch 25/100: 100%|█| 225/225 [02:20<00:00,  1.60it/s, total=0.0801, score=0.003\n",
            "Epoch 25 | train 0.0767 | val 0.0699\n",
            "Epoch 26/100: 100%|█| 225/225 [02:19<00:00,  1.61it/s, total=0.0631, score=0.019\n",
            "Epoch 26 | train 0.0724 | val 0.0905\n",
            "Epoch 27/100: 100%|█| 225/225 [02:21<00:00,  1.59it/s, total=0.0484, score=0.003\n",
            "Epoch 27 | train 0.0729 | val 0.0643\n",
            "Epoch 28/100: 100%|█| 225/225 [02:23<00:00,  1.57it/s, total=0.0597, score=0.004\n",
            "Epoch 28 | train 0.0715 | val 0.0824\n",
            "LR reduced from 0.000031 to 0.000016\n",
            "Epoch 29/100: 100%|█| 225/225 [02:20<00:00,  1.60it/s, total=0.0877, score=0.009\n",
            "Epoch 29 | train 0.0703 | val 0.0743\n",
            "Epoch 30/100: 100%|█| 225/225 [02:21<00:00,  1.60it/s, total=0.0564, score=0.005\n",
            "Epoch 30 | train 0.0672 | val 0.0794\n",
            "Epoch 31/100: 100%|█| 225/225 [02:23<00:00,  1.57it/s, total=0.0384, score=0.012\n",
            "Epoch 31 | train 0.0638 | val 0.0628\n",
            "Epoch 32/100: 100%|█| 225/225 [02:19<00:00,  1.61it/s, total=0.0222, score=0.004\n",
            "Epoch 32 | train 0.0757 | val 0.0600\n",
            "✅ New best model saved with val loss 0.0600\n",
            "Epoch 33/100: 100%|█| 225/225 [02:18<00:00,  1.62it/s, total=0.0178, score=0.001\n",
            "Epoch 33 | train 0.0652 | val 0.0672\n",
            "Epoch 34/100: 100%|█| 225/225 [02:17<00:00,  1.63it/s, total=0.0236, score=0.004\n",
            "Epoch 34 | train 0.0668 | val 0.0627\n",
            "Epoch 35/100: 100%|█| 225/225 [02:19<00:00,  1.61it/s, total=0.0517, score=0.002\n",
            "Epoch 35 | train 0.0649 | val 0.0695\n",
            "Epoch 36/100: 100%|█| 225/225 [02:16<00:00,  1.64it/s, total=0.0177, score=0.001\n",
            "Epoch 36 | train 0.0688 | val 0.0653\n",
            "LR reduced from 0.000016 to 0.000008\n",
            "Epoch 37/100: 100%|█| 225/225 [02:17<00:00,  1.64it/s, total=0.1322, score=0.016\n",
            "Epoch 37 | train 0.0640 | val 0.0701\n",
            "Epoch 38/100: 100%|█| 225/225 [02:15<00:00,  1.66it/s, total=0.0577, score=0.010\n",
            "Epoch 38 | train 0.0730 | val 0.0647\n",
            "Epoch 39/100: 100%|█| 225/225 [02:15<00:00,  1.67it/s, total=0.0545, score=0.003\n",
            "Epoch 39 | train 409.3613 | val 0.0762\n",
            "Epoch 40/100: 100%|█| 225/225 [02:15<00:00,  1.66it/s, total=0.0434, score=0.003\n",
            "Epoch 40 | train 1264.8631 | val 0.0684\n",
            "LR reduced from 0.000008 to 0.000004\n",
            "Epoch 41/100: 100%|█| 225/225 [02:15<00:00,  1.66it/s, total=0.0652, score=0.002\n",
            "Epoch 41 | train 0.0664 | val 0.0753\n",
            "Epoch 42/100: 100%|█| 225/225 [02:13<00:00,  1.68it/s, total=0.0572, score=0.001\n",
            "Epoch 42 | train 986.5848 | val 0.0609\n",
            "Epoch 43/100: 100%|█| 225/225 [02:16<00:00,  1.65it/s, total=0.0515, score=0.004\n",
            "Epoch 43 | train 0.0625 | val 0.0661\n",
            "Epoch 44/100: 100%|█| 225/225 [02:17<00:00,  1.63it/s, total=0.0322, score=0.004\n",
            "Epoch 44 | train 0.0609 | val 0.0735\n",
            "LR reduced from 0.000004 to 0.000002\n",
            "Epoch 45/100: 100%|█| 225/225 [02:19<00:00,  1.62it/s, total=0.0686, score=0.016\n",
            "Epoch 45 | train 0.0709 | val 0.0729\n",
            "Epoch 46/100: 100%|█| 225/225 [02:15<00:00,  1.65it/s, total=0.0748, score=0.001\n",
            "Epoch 46 | train 0.0679 | val 0.0746\n",
            "Epoch 47/100: 100%|█| 225/225 [02:14<00:00,  1.67it/s, total=0.0920, score=0.006\n",
            "Epoch 47 | train 0.0635 | val 0.0590\n",
            "✅ New best model saved with val loss 0.0590\n",
            "Epoch 48/100: 100%|█| 225/225 [02:17<00:00,  1.64it/s, total=0.1609, score=0.011\n",
            "Epoch 48 | train 0.0667 | val 0.0595\n",
            "Epoch 49/100: 100%|█| 225/225 [02:20<00:00,  1.60it/s, total=0.0481, score=0.006\n",
            "Epoch 49 | train 0.0716 | val 0.0603\n",
            "Epoch 50/100: 100%|█| 225/225 [02:16<00:00,  1.64it/s, total=0.0232, score=0.001\n",
            "Epoch 50 | train 0.0652 | val 0.0702\n",
            "Epoch 51/100: 100%|█| 225/225 [02:19<00:00,  1.61it/s, total=0.0359, score=0.003\n",
            "Epoch 51 | train 0.0640 | val 0.0657\n",
            "LR reduced from 0.000002 to 0.000001\n",
            "Epoch 52/100: 100%|█| 225/225 [02:18<00:00,  1.63it/s, total=0.0297, score=0.004\n",
            "Epoch 52 | train 0.0648 | val 0.0651\n",
            "Epoch 53/100: 100%|█| 225/225 [02:18<00:00,  1.63it/s, total=0.0189, score=0.004\n",
            "Epoch 53 | train 0.0633 | val 0.0779\n",
            "Epoch 54/100: 100%|█| 225/225 [02:18<00:00,  1.62it/s, total=0.0423, score=0.001\n",
            "Epoch 54 | train 0.0703 | val 0.0612\n",
            "Epoch 55/100: 100%|█| 225/225 [02:15<00:00,  1.66it/s, total=0.0283, score=0.009\n",
            "Epoch 55 | train 0.0662 | val 0.0714\n",
            "LR reduced from 0.000001 to 0.000000\n",
            "Epoch 56/100: 100%|█| 225/225 [02:19<00:00,  1.62it/s, total=0.1180, score=0.004\n",
            "Epoch 56 | train 0.0635 | val 0.0645\n",
            "Epoch 57/100: 100%|█| 225/225 [02:20<00:00,  1.60it/s, total=0.0206, score=0.001\n",
            "Epoch 57 | train 1598.7866 | val 0.0721\n",
            "Epoch 58/100: 100%|█| 225/225 [02:22<00:00,  1.58it/s, total=0.0482, score=0.006\n",
            "Epoch 58 | train 0.0680 | val 0.0683\n",
            "Epoch 59/100: 100%|█| 225/225 [02:19<00:00,  1.61it/s, total=0.0374, score=0.004\n",
            "Epoch 59 | train 0.0623 | val 0.0590\n",
            "LR reduced from 0.000000 to 0.000000\n",
            "Epoch 60/100: 100%|█| 225/225 [02:14<00:00,  1.67it/s, total=0.0941, score=0.009\n",
            "Epoch 60 | train 3625.6629 | val 0.0737\n",
            "Epoch 61/100: 100%|█| 225/225 [02:15<00:00,  1.66it/s, total=0.0366, score=0.004\n",
            "Epoch 61 | train 0.0679 | val 0.0774\n",
            "Epoch 62/100: 100%|█| 225/225 [02:15<00:00,  1.66it/s, total=0.0571, score=0.010\n",
            "Epoch 62 | train 0.0689 | val 0.0648\n",
            "Epoch 63/100: 100%|█| 225/225 [02:14<00:00,  1.67it/s, total=0.0890, score=0.003\n",
            "Epoch 63 | train 0.0632 | val 0.0663\n",
            "LR reduced from 0.000000 to 0.000000\n",
            "Epoch 64/100: 100%|█| 225/225 [02:17<00:00,  1.64it/s, total=0.0730, score=0.005\n",
            "Epoch 64 | train 0.0635 | val 0.0629\n",
            "Epoch 65/100: 100%|█| 225/225 [02:17<00:00,  1.64it/s, total=0.1114, score=0.012\n",
            "Epoch 65 | train 0.0652 | val 0.0641\n",
            "Epoch 66/100: 100%|█| 225/225 [02:18<00:00,  1.62it/s, total=0.0322, score=0.003\n",
            "Epoch 66 | train 0.0652 | val 0.0591\n",
            "Epoch 67/100: 100%|█| 225/225 [02:20<00:00,  1.60it/s, total=0.0320, score=0.005\n",
            "Epoch 67 | train 0.0645 | val 0.0647\n",
            "LR reduced from 0.000000 to 0.000000\n",
            "🛑 Early stopping at epoch 67 (no val improvement for 20 epochs).\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}