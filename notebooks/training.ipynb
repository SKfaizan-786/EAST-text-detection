{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed2e8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now in: c:\\Users\\faizan\\Desktop\\EAST\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")  # move up from notebooks to repo root\n",
    "print(\"Now in:\", os.getcwd())\n",
    "# Add project root to sys.path so 'src' can be imported\n",
    "import sys\n",
    "project_root = os.path.abspath(os.getcwd())\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80fded25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faizan\\Desktop\\EAST\n",
      "Dataset length: 1000\n",
      "First 3 image paths: ['data/icdar2015/train_images\\\\img_1.jpg', 'data/icdar2015/train_images\\\\img_10.jpg', 'data/icdar2015/train_images\\\\img_100.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "from src.dataset import EASTDataset\n",
    "\n",
    "ds = EASTDataset(\"data/icdar2015/train_images\", \"data/icdar2015/train_maps\", size=512)\n",
    "\n",
    "print(\"Dataset length:\", len(ds))\n",
    "print(\"First 3 image paths:\", ds.img_paths[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cae46cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images : torch.Size([4, 3, 512, 512])\n",
      "Scores : torch.Size([4, 1, 512, 512])\n",
      "Geos   : torch.Size([4, 8, 512, 512])\n",
      "Nmaps  : torch.Size([4, 1, 512, 512])\n",
      "Image range: -2.1179039478302 to 2.640000104904175\n",
      "Score unique values: tensor([0., 1.])\n",
      "Geo stats: mean 0.0132293701171875 std 7.47803258895874\n",
      "Nmap stats (on positive pixels): mean 127.58235168457031 std 35.18562698364258\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from src.dataset import EASTDataset\n",
    "\n",
    "# Create a small dataset instance\n",
    "train_dataset = EASTDataset(\n",
    "    img_dir=\"data/icdar2015/train_images\",\n",
    "    map_dir=\"data/icdar2015/train_maps\",\n",
    "    size=512,              # keep same as paper\n",
    "    training=True          # enable random cropping/augmentation\n",
    ")\n",
    "\n",
    "# Try a small dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "# Fetch one batch, now including the nmap\n",
    "imgs, scores, geos, nmaps = next(iter(train_loader))\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"Images :\", imgs.shape)    # expect [B, 3, 512, 512]\n",
    "print(\"Scores :\", scores.shape)  # expect [B, 1, 512, 512]\n",
    "print(\"Geos   :\", geos.shape)    # expect [B, 8, 512, 512]\n",
    "print(\"Nmaps  :\", nmaps.shape)   # expect [B, 1, 512, 512]\n",
    "\n",
    "# Check value ranges and properties\n",
    "print(\"Image range:\", imgs.min().item(), \"to\", imgs.max().item())\n",
    "print(\"Score unique values:\", torch.unique(scores))\n",
    "print(\"Geo stats: mean\", geos.mean().item(), \"std\", geos.std().item())\n",
    "\n",
    "# Verify nmap has non-zero values where score is positive\n",
    "print(\"Nmap stats (on positive pixels): mean\", nmaps[scores > 0].mean().item(), \"std\", nmaps[scores > 0].std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74fb9abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\faizan/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score map: torch.Size([1, 1, 512, 512])\n",
      "Geo map: torch.Size([1, 8, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.model import EAST\n",
    "\n",
    "model = EAST(pretrained=False)\n",
    "dummy = torch.randn(1, 3, 512, 512)  # batch of one\n",
    "score, geo = model(dummy)\n",
    "\n",
    "print(\"Score map:\", score.shape)  # expect [1, 1, 512, 512]\n",
    "print(\"Geo map:\", geo.shape)      # expect [1, 8, 512, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e40f27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 0.1503923237323761\n",
      "Score loss: 0.020851217210292816\n",
      "Geo loss  : 0.12954111397266388\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.model import EAST\n",
    "from src.losses import EASTLoss\n",
    "\n",
    "# Assuming imgs, scores, geos, and nmaps are already loaded from your DataLoader test.\n",
    "# If not, you'd need to run the DataLoader test cell again to get these variables.\n",
    "# You might want to move these to a CUDA device if available.\n",
    "# imgs = imgs.to('cuda')\n",
    "# ... and so on for the other tensors\n",
    "\n",
    "# Instantiate the model and criterion\n",
    "model = EAST(pretrained=True)  # Use pretrained=True to follow the paper's method\n",
    "model.eval()  # Set model to evaluation mode for a clean forward pass test\n",
    "\n",
    "# Perform a forward pass to get predictions\n",
    "with torch.no_grad():\n",
    "    pred_score, pred_geo = model(imgs)\n",
    "\n",
    "# Instantiate the loss function\n",
    "criterion = EASTLoss()\n",
    "\n",
    "# Compute the loss using your predictions and ground truth maps\n",
    "total_loss, score_loss, geo_loss = criterion(pred_score, pred_geo, scores, geos, nmaps)\n",
    "\n",
    "# Print the results\n",
    "print(\"Total loss:\", total_loss.item())\n",
    "print(\"Score loss:\", score_loss.item())\n",
    "print(\"Geo loss  :\", geo_loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "east_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
